{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm19gFuvGbQT",
        "outputId": "05be767a-fb46-448b-c07e-6529c8ffc144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# OPTIMIZED ADVERSARIAL TESTING & TRAINING PIPELINE\n",
        "# Audio Deepfake Detection with ResNet-18\n",
        "# =============================================\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import time\n",
        "\n",
        "# =============================================\n",
        "# CONFIGURATION\n",
        "# =============================================\n",
        "\n",
        "class Config:\n",
        "    # Paths\n",
        "    DATA_ROOT = \"/content/drive/MyDrive/CombinedDataset\"\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/CombinedDataset/results_resnet18/best_resnet18.pth\"\n",
        "    OUT_DIR = \"/content/drive/MyDrive/CombinedDataset/adversarial_results\"\n",
        "\n",
        "    # Model settings\n",
        "    IMG_SIZE = 224\n",
        "    BATCH_SIZE = 32\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Adversarial attack settings\n",
        "    EPSILON_VALUES = [0.001, 0.005, 0.01, 0.02, 0.05]\n",
        "    PGD_EPSILON = 0.01\n",
        "    PGD_ALPHA = 0.002\n",
        "    PGD_ITERATIONS = 10\n",
        "\n",
        "    # Adversarial training settings (OPTIMIZED)\n",
        "    ADV_TRAIN_EPOCHS = 10\n",
        "    ADV_TRAIN_LR = 1e-4\n",
        "    ADV_TRAIN_EPSILON = 0.01\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Optimization settings\n",
        "    USE_AMP = True  # Automatic Mixed Precision\n",
        "    NUM_WORKERS = 2  # DataLoader workers\n",
        "\n",
        "    # Reproducibility\n",
        "    SEED = 42\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(config.SEED)\n",
        "torch.manual_seed(config.SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(config.SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "print(\"ADVERSARIAL ROBUSTNESS ANALYSIS\")\n",
        "\n",
        "print(f\"\\nDevice: {config.DEVICE}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"Mixed Precision: {config.USE_AMP}\")\n",
        "print(f\"Output Directory: {config.OUT_DIR}\")\n",
        "\n",
        "# =============================================\n",
        "# DATASET CLASS\n",
        "# =============================================\n",
        "\n",
        "class MelSpectrogramDataset(Dataset):\n",
        "    \"\"\"Dataset for loading mel spectrogram .npy files\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, img_size=224, augment=False):\n",
        "        self.root_dir = os.path.join(root_dir, \"mel\")\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "        self.files = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load file paths\n",
        "        for label_name, label_id in [('real', 0), ('fake', 1)]:\n",
        "            folder = os.path.join(self.root_dir, label_name)\n",
        "            if not os.path.exists(folder):\n",
        "                raise ValueError(f\"Folder not found: {folder}\")\n",
        "\n",
        "            for filename in os.listdir(folder):\n",
        "                if filename.lower().endswith('.npy'):\n",
        "                    self.files.append(os.path.join(folder, filename))\n",
        "                    self.labels.append(label_id)\n",
        "\n",
        "        if len(self.files) == 0:\n",
        "            raise ValueError(f\"No .npy files found in {self.root_dir}\")\n",
        "\n",
        "        # Shuffle dataset\n",
        "        combined = list(zip(self.files, self.labels))\n",
        "        np.random.shuffle(combined)\n",
        "        self.files, self.labels = zip(*combined)\n",
        "\n",
        "        # Transforms\n",
        "        self.to_pil = transforms.ToPILImage()\n",
        "        self.resize = transforms.Resize((img_size, img_size))\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.normalize = transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load mel spectrogram\n",
        "        mel_spec = np.load(self.files[idx])\n",
        "\n",
        "        # Convert to 3-channel\n",
        "        if mel_spec.ndim == 2:\n",
        "            mel_spec = np.stack([mel_spec] * 3, axis=-1)\n",
        "\n",
        "        # Normalize to [0, 255]\n",
        "        mel_min, mel_max = mel_spec.min(), mel_spec.max()\n",
        "        mel_normalized = ((mel_spec - mel_min) / (mel_max - mel_min + 1e-9) * 255).astype(np.uint8)\n",
        "\n",
        "        # Convert to PIL and apply transforms\n",
        "        image = self.to_pil(mel_normalized)\n",
        "        image = self.resize(image)\n",
        "        image = self.to_tensor(image)\n",
        "        image = self.normalize(image)\n",
        "\n",
        "        return image, self.labels[idx]\n",
        "\n",
        "# =============================================\n",
        "# LOAD MODEL\n",
        "# =============================================\n",
        "\n",
        "def load_model(model_path, device):\n",
        "    \"\"\"Load pretrained ResNet-18 model\"\"\"\n",
        "    print(\"\\nLoading model...\")\n",
        "    model = models.resnet18(weights=None)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, 2)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Model loaded from: {model_path}\")\n",
        "    return model\n",
        "\n",
        "# =============================================\n",
        "# ADVERSARIAL ATTACKS\n",
        "# =============================================\n",
        "\n",
        "def fgsm_attack(model, images, labels, epsilon):\n",
        "    \"\"\"Fast Gradient Sign Method attack\"\"\"\n",
        "    images.requires_grad = True\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    data_grad = images.grad.data\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_images = images + epsilon * sign_data_grad\n",
        "    perturbed_images = torch.clamp(perturbed_images, images.min(), images.max())\n",
        "\n",
        "    return perturbed_images.detach()\n",
        "\n",
        "def pgd_attack(model, images, labels, epsilon, alpha, num_iterations):\n",
        "    \"\"\"Projected Gradient Descent attack\"\"\"\n",
        "    original_images = images.clone().detach()\n",
        "    perturbed_images = images.clone().detach()\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        perturbed_images.requires_grad = True\n",
        "\n",
        "        outputs = model(perturbed_images)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        data_grad = perturbed_images.grad.data\n",
        "        perturbed_images = perturbed_images.detach() + alpha * data_grad.sign()\n",
        "\n",
        "        # Project back to epsilon ball\n",
        "        perturbation = torch.clamp(perturbed_images - original_images, -epsilon, epsilon)\n",
        "        perturbed_images = torch.clamp(original_images + perturbation,\n",
        "                                       original_images.min(), original_images.max()).detach()\n",
        "\n",
        "    return perturbed_images\n",
        "\n",
        "# =============================================\n",
        "# EVALUATION FUNCTION\n",
        "# =============================================\n",
        "\n",
        "def evaluate_model(model, dataloader, device, attack_fn=None, attack_params=None, desc=\"Evaluating\"):\n",
        "    \"\"\"Evaluate model on clean or adversarial examples\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    context = torch.no_grad() if attack_fn is None else torch.enable_grad()\n",
        "\n",
        "    with context:\n",
        "        for images, labels in tqdm(dataloader, desc=desc, leave=False):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            # Generate adversarial examples if needed\n",
        "            if attack_fn is not None:\n",
        "                images = attack_fn(model, images, labels, **attack_params)\n",
        "\n",
        "            # Get predictions\n",
        "            with torch.no_grad():\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    accuracy = (all_preds == all_labels).mean()\n",
        "\n",
        "    return accuracy, all_preds, all_labels\n",
        "\n",
        "# =============================================\n",
        "# ADVERSARIAL TRAINING (OPTIMIZED)\n",
        "# =============================================\n",
        "\n",
        "def adversarial_training(model, train_loader, val_loader, config):\n",
        "    \"\"\"Train model with adversarial examples using mixed precision\"\"\"\n",
        "\n",
        "    print(\"ADVERSARIAL TRAINING (OPTIMIZED)\")\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=config.ADV_TRAIN_LR,\n",
        "        weight_decay=config.WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    # Mixed precision scaler\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.USE_AMP and torch.cuda.is_available() else None\n",
        "    use_amp = config.USE_AMP and torch.cuda.is_available()\n",
        "\n",
        "    print(f\"Optimizer: Adam (LR={config.ADV_TRAIN_LR})\")\n",
        "    print(f\"Mixed Precision: {'Enabled' if use_amp else 'Disabled'}\")\n",
        "    print(f\"Training Epsilon: {config.ADV_TRAIN_EPSILON}\")\n",
        "    print(f\"Epochs: {config.ADV_TRAIN_EPOCHS}\")\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_acc': [], 'epoch_time': []}\n",
        "\n",
        "    for epoch in range(config.ADV_TRAIN_EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.ADV_TRAIN_EPOCHS}\")\n",
        "\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
        "            images = images.to(config.DEVICE, non_blocking=True)\n",
        "            labels = labels.to(config.DEVICE, non_blocking=True)\n",
        "\n",
        "            # Split batch: 50% clean, 50% adversarial\n",
        "            batch_size = images.size(0)\n",
        "            half_batch = batch_size // 2\n",
        "\n",
        "            clean_images = images[:half_batch]\n",
        "            clean_labels = labels[:half_batch]\n",
        "\n",
        "            adv_images_raw = images[half_batch:]\n",
        "            adv_labels = labels[half_batch:]\n",
        "\n",
        "            # Generate adversarial examples\n",
        "            adv_images = fgsm_attack(model, adv_images_raw, adv_labels, config.ADV_TRAIN_EPSILON)\n",
        "\n",
        "            # Combine clean and adversarial\n",
        "            combined_images = torch.cat([clean_images, adv_images], dim=0)\n",
        "            combined_labels = torch.cat([clean_labels, adv_labels], dim=0)\n",
        "\n",
        "            # Forward pass with mixed precision\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            if use_amp:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model(combined_images)\n",
        "                    loss = criterion(outputs, combined_labels)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                outputs = model(combined_images)\n",
        "                loss = criterion(outputs, combined_labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * combined_images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += combined_labels.size(0)\n",
        "            correct += (predicted == combined_labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        # Validation phase\n",
        "        val_acc, _, _ = evaluate_model(model, val_loader, config.DEVICE, desc=\"Validation\")\n",
        "\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "\n",
        "        # Save history\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_acc'].append(epoch_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['epoch_time'].append(epoch_time)\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\nTrain Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}\")\n",
        "        print(f\"Val Acc:    {val_acc:.4f}\")\n",
        "        print(f\"Epoch Time: {epoch_time/60:.2f} minutes\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(),\n",
        "                      os.path.join(config.OUT_DIR, \"adversarial_trained_model.pth\"))\n",
        "            print(f\"Best model saved (Val Acc: {val_acc:.4f})\")\n",
        "\n",
        "    total_time = sum(history['epoch_time'])\n",
        "\n",
        "    print(f\"Training Complete\")\n",
        "    print(f\"Total Time: {total_time/60:.2f} minutes\")\n",
        "    print(f\"Average Time per Epoch: {total_time/config.ADV_TRAIN_EPOCHS/60:.2f} minutes\")\n",
        "    print(f\"Best Val Accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# =============================================\n",
        "# MAIN EXECUTION\n",
        "# =============================================\n",
        "\n",
        "\n",
        "print(\"LOADING DATASETS\")\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "test_dataset = MelSpectrogramDataset(\n",
        "    os.path.join(config.DATA_ROOT, \"test\"),\n",
        "    img_size=config.IMG_SIZE\n",
        ")\n",
        "\n",
        "train_dataset = MelSpectrogramDataset(\n",
        "    os.path.join(config.DATA_ROOT, \"train\"),\n",
        "    img_size=config.IMG_SIZE\n",
        ")\n",
        "\n",
        "val_dataset = MelSpectrogramDataset(\n",
        "    os.path.join(config.DATA_ROOT, \"val\"),\n",
        "    img_size=config.IMG_SIZE\n",
        ")\n",
        "\n",
        "# Create dataloaders with optimizations\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"\\nTest:  {len(test_dataset)} samples ({len(test_loader)} batches)\")\n",
        "print(f\"Train: {len(train_dataset)} samples ({len(train_loader)} batches)\")\n",
        "print(f\"Val:   {len(val_dataset)} samples ({len(val_loader)} batches)\")\n",
        "\n",
        "# Load original model\n",
        "original_model = load_model(config.MODEL_PATH, config.DEVICE)\n",
        "\n",
        "# =============================================\n",
        "# PHASE 1: TEST ORIGINAL MODEL\n",
        "# =============================================\n",
        "\n",
        "\n",
        "print(\"PHASE 1: ORIGINAL MODEL EVALUATION\")\n",
        "\n",
        "\n",
        "print(\"\\n1. Clean Test Accuracy:\")\n",
        "clean_acc, clean_preds, clean_labels = evaluate_model(\n",
        "    original_model, test_loader, config.DEVICE, desc=\"Clean Test\"\n",
        ")\n",
        "print(f\"   Accuracy: {clean_acc*100:.2f}%\")\n",
        "\n",
        "print(\"\\n2. FGSM Attack Results:\")\n",
        "fgsm_results = {}\n",
        "for epsilon in config.EPSILON_VALUES:\n",
        "    acc, _, _ = evaluate_model(\n",
        "        original_model, test_loader, config.DEVICE,\n",
        "        attack_fn=fgsm_attack,\n",
        "        attack_params={'epsilon': epsilon},\n",
        "        desc=f\"FGSM ε={epsilon}\"\n",
        "    )\n",
        "    fgsm_results[epsilon] = acc\n",
        "    print(f\"   ε = {epsilon:.3f}: {acc*100:.2f}%\")\n",
        "\n",
        "print(\"\\n3. PGD Attack Result:\")\n",
        "pgd_start = time.time()\n",
        "pgd_acc, pgd_preds, pgd_labels = evaluate_model(\n",
        "    original_model, test_loader, config.DEVICE,\n",
        "    attack_fn=pgd_attack,\n",
        "    attack_params={\n",
        "        'epsilon': config.PGD_EPSILON,\n",
        "        'alpha': config.PGD_ALPHA,\n",
        "        'num_iterations': config.PGD_ITERATIONS\n",
        "    },\n",
        "    desc=\"PGD Attack\"\n",
        ")\n",
        "pgd_time = time.time() - pgd_start\n",
        "print(f\"   Accuracy: {pgd_acc*100:.2f}%\")\n",
        "print(f\"   Attack Time: {pgd_time:.1f} seconds\")\n",
        "\n",
        "# Print summary\n",
        "\n",
        "print(\"ORIGINAL MODEL SUMMARY\")\n",
        "print(f\"Clean Accuracy:        {clean_acc*100:.2f}%\")\n",
        "print(f\"FGSM-0.01 Accuracy:    {fgsm_results[0.01]*100:.2f}%\")\n",
        "print(f\"PGD-0.01 Accuracy:     {pgd_acc*100:.2f}%\")\n",
        "print(f\"Robustness Drop (PGD): {(clean_acc - pgd_acc)*100:.2f}%\")\n",
        "\n",
        "# =============================================\n",
        "# PHASE 2: ADVERSARIAL TRAINING\n",
        "# =============================================\n",
        "\n",
        "\n",
        "print(\"PHASE 2: ADVERSARIAL TRAINING\")\n",
        "\n",
        "\n",
        "response = input(\"\\nProceed with adversarial training? (y/n): \")\n",
        "\n",
        "if response.lower() == 'y':\n",
        "    # Load fresh model for adversarial training\n",
        "    adv_model = load_model(config.MODEL_PATH, config.DEVICE)\n",
        "\n",
        "    # Train with adversarial examples\n",
        "    adv_model, adv_history = adversarial_training(adv_model, train_loader, val_loader, config)\n",
        "\n",
        "    # =============================================\n",
        "    # PHASE 3: TEST ADVERSARIALLY TRAINED MODEL\n",
        "    # =============================================\n",
        "\n",
        "    print(\"PHASE 3: ADVERSARIALLY TRAINED MODEL EVALUATION\")\n",
        "\n",
        "\n",
        "    print(\"\\n1. Clean Test Accuracy:\")\n",
        "    adv_clean_acc, _, _ = evaluate_model(\n",
        "        adv_model, test_loader, config.DEVICE, desc=\"Clean Test\"\n",
        "    )\n",
        "    print(f\"   Accuracy: {adv_clean_acc*100:.2f}%\")\n",
        "    print(f\"   Change: {(adv_clean_acc - clean_acc)*100:+.2f}%\")\n",
        "\n",
        "    print(\"\\n2. FGSM Attack Results:\")\n",
        "    adv_fgsm_results = {}\n",
        "    for epsilon in config.EPSILON_VALUES:\n",
        "        acc, _, _ = evaluate_model(\n",
        "            adv_model, test_loader, config.DEVICE,\n",
        "            attack_fn=fgsm_attack,\n",
        "            attack_params={'epsilon': epsilon},\n",
        "            desc=f\"FGSM ε={epsilon}\"\n",
        "        )\n",
        "        adv_fgsm_results[epsilon] = acc\n",
        "        improvement = (acc - fgsm_results[epsilon]) * 100\n",
        "        print(f\"   ε = {epsilon:.3f}: {acc*100:.2f}% (Δ {improvement:+.2f}%)\")\n",
        "\n",
        "    print(\"\\n3. PGD Attack Result:\")\n",
        "    adv_pgd_acc, _, _ = evaluate_model(\n",
        "        adv_model, test_loader, config.DEVICE,\n",
        "        attack_fn=pgd_attack,\n",
        "        attack_params={\n",
        "            'epsilon': config.PGD_EPSILON,\n",
        "            'alpha': config.PGD_ALPHA,\n",
        "            'num_iterations': config.PGD_ITERATIONS\n",
        "        },\n",
        "        desc=\"PGD Attack\"\n",
        "    )\n",
        "    pgd_improvement = (adv_pgd_acc - pgd_acc) * 100\n",
        "    print(f\"   Accuracy: {adv_pgd_acc*100:.2f}% (Δ {pgd_improvement:+.2f}%)\")\n",
        "\n",
        "    # =============================================\n",
        "    # GENERATE VISUALIZATIONS\n",
        "    # =============================================\n",
        "\n",
        "\n",
        "    print(\"GENERATING VISUALIZATIONS\")\n",
        "\n",
        "\n",
        "    # Plot 1: Robustness Comparison\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # FGSM comparison\n",
        "    epsilons = list(fgsm_results.keys())\n",
        "    original_fgsm = [fgsm_results[e]*100 for e in epsilons]\n",
        "    adversarial_fgsm = [adv_fgsm_results[e]*100 for e in epsilons]\n",
        "\n",
        "    ax1.plot(epsilons, original_fgsm, 'o-', label='Original Model', linewidth=2, markersize=8)\n",
        "    ax1.plot(epsilons, adversarial_fgsm, 's-', label='Adversarially Trained', linewidth=2, markersize=8)\n",
        "    ax1.set_xlabel('Epsilon (ε)', fontsize=12)\n",
        "    ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax1.set_title('FGSM Attack Robustness Comparison', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=11)\n",
        "    ax1.grid(alpha=0.3)\n",
        "    ax1.set_ylim([0, 105])\n",
        "\n",
        "    # Overall comparison\n",
        "    categories = ['Clean', 'FGSM\\nε=0.01', 'PGD\\nε=0.01']\n",
        "    original_scores = [clean_acc*100, fgsm_results[0.01]*100, pgd_acc*100]\n",
        "    adversarial_scores = [adv_clean_acc*100, adv_fgsm_results[0.01]*100, adv_pgd_acc*100]\n",
        "\n",
        "    x = np.arange(len(categories))\n",
        "    width = 0.35\n",
        "\n",
        "    bars1 = ax2.bar(x - width/2, original_scores, width, label='Original Model', color='steelblue')\n",
        "    bars2 = ax2.bar(x + width/2, adversarial_scores, width, label='Adversarially Trained', color='coral')\n",
        "\n",
        "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax2.set_title('Overall Performance Comparison', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(categories, fontsize=11)\n",
        "    ax2.legend(fontsize=11)\n",
        "    ax2.grid(alpha=0.3, axis='y')\n",
        "    ax2.set_ylim([0, 105])\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUT_DIR, 'adversarial_comparison.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(\"Comparison plot saved\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot 2: Training History\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    epochs = range(1, len(adv_history['train_loss']) + 1)\n",
        "\n",
        "    ax1.plot(epochs, adv_history['train_loss'], 'o-', linewidth=2, markersize=8, color='crimson')\n",
        "    ax1.set_xlabel('Epoch', fontsize=12)\n",
        "    ax1.set_ylabel('Loss', fontsize=12)\n",
        "    ax1.set_title('Adversarial Training Loss', fontsize=14, fontweight='bold')\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    ax2.plot(epochs, adv_history['train_acc'], 'o-', label='Train Accuracy', linewidth=2, markersize=8)\n",
        "    ax2.plot(epochs, adv_history['val_acc'], 's-', label='Val Accuracy', linewidth=2, markersize=8)\n",
        "    ax2.set_xlabel('Epoch', fontsize=12)\n",
        "    ax2.set_ylabel('Accuracy', fontsize=12)\n",
        "    ax2.set_title('Adversarial Training Accuracy', fontsize=14, fontweight='bold')\n",
        "    ax2.legend(fontsize=11)\n",
        "    ax2.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUT_DIR, 'adversarial_training_history.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(\"Training history plot saved\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot 3: Confusion Matrices\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Original model confusion matrix\n",
        "    cm_original = confusion_matrix(clean_labels, clean_preds)\n",
        "    sns.heatmap(cm_original, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
        "                xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "    ax1.set_title('Original Model (Clean Test)', fontsize=14, fontweight='bold')\n",
        "    ax1.set_ylabel('True Label', fontsize=12)\n",
        "    ax1.set_xlabel('Predicted Label', fontsize=12)\n",
        "\n",
        "    # Adversarial model under PGD attack\n",
        "    adv_pgd_preds = evaluate_model(\n",
        "        adv_model, test_loader, config.DEVICE,\n",
        "        attack_fn=pgd_attack,\n",
        "        attack_params={'epsilon': config.PGD_EPSILON, 'alpha': config.PGD_ALPHA,\n",
        "                      'num_iterations': config.PGD_ITERATIONS}\n",
        "    )[1]\n",
        "    cm_adv = confusion_matrix(pgd_labels, adv_pgd_preds)\n",
        "    sns.heatmap(cm_adv, annot=True, fmt='d', cmap='Oranges', ax=ax2,\n",
        "                xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "    ax2.set_title('Adversarially Trained (PGD Attack)', fontsize=14, fontweight='bold')\n",
        "    ax2.set_ylabel('True Label', fontsize=12)\n",
        "    ax2.set_xlabel('Predicted Label', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUT_DIR, 'confusion_matrices.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(\"Confusion matrices saved\")\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to JSON\n",
        "    results = {\n",
        "        'original_model': {\n",
        "            'clean_accuracy': float(clean_acc),\n",
        "            'fgsm_results': {str(k): float(v) for k, v in fgsm_results.items()},\n",
        "            'pgd_accuracy': float(pgd_acc)\n",
        "        },\n",
        "        'adversarial_model': {\n",
        "            'clean_accuracy': float(adv_clean_acc),\n",
        "            'fgsm_results': {str(k): float(v) for k, v in adv_fgsm_results.items()},\n",
        "            'pgd_accuracy': float(adv_pgd_acc)\n",
        "        },\n",
        "        'improvements': {\n",
        "            'clean_accuracy_change': float(adv_clean_acc - clean_acc),\n",
        "            'fgsm_0.01_improvement': float(adv_fgsm_results[0.01] - fgsm_results[0.01]),\n",
        "            'pgd_improvement': float(adv_pgd_acc - pgd_acc)\n",
        "        },\n",
        "        'training_history': {\n",
        "            'train_loss': [float(x) for x in adv_history['train_loss']],\n",
        "            'train_acc': [float(x) for x in adv_history['train_acc']],\n",
        "            'val_acc': [float(x) for x in adv_history['val_acc']],\n",
        "            'epoch_times': [float(x) for x in adv_history['epoch_time']]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(config.OUT_DIR, 'adversarial_results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(\"Results saved to adversarial_results.json\")\n",
        "\n",
        "    # =============================================\n",
        "    # FINAL SUMMARY\n",
        "    # =============================================\n",
        "\n",
        "\n",
        "    print(\"FINAL SUMMARY\")\n",
        "\n",
        "\n",
        "    print(\"\\n ORIGINAL MODEL:\")\n",
        "    print(f\"   Clean Accuracy:     {clean_acc*100:.2f}%\")\n",
        "    print(f\"   FGSM-0.01 Accuracy: {fgsm_results[0.01]*100:.2f}%\")\n",
        "    print(f\"   PGD-0.01 Accuracy:  {pgd_acc*100:.2f}%\")\n",
        "    print(f\"   Robustness Drop:    {(clean_acc - pgd_acc)*100:.2f}%\")\n",
        "\n",
        "    print(\"\\n  ADVERSARIALLY TRAINED MODEL:\")\n",
        "    print(f\"   Clean Accuracy:     {adv_clean_acc*100:.2f}% ({(adv_clean_acc-clean_acc)*100:+.2f}%)\")\n",
        "    print(f\"   FGSM-0.01 Accuracy: {adv_fgsm_results[0.01]*100:.2f}% ({(adv_fgsm_results[0.01]-fgsm_results[0.01])*100:+.2f}%)\")\n",
        "    print(f\"   PGD-0.01 Accuracy:  {adv_pgd_acc*100:.2f}% ({(adv_pgd_acc-pgd_acc)*100:+.2f}%)\")\n",
        "    print(f\"   Robustness Drop:    {(adv_clean_acc - adv_pgd_acc)*100:.2f}%\")\n",
        "\n",
        "    print(\"\\n IMPROVEMENTS:\")\n",
        "    print(f\"   PGD Robustness Gain:      {(adv_pgd_acc - pgd_acc)*100:+.2f} percentage points\")\n",
        "    print(f\"   FGSM-0.01 Robustness Gain: {(adv_fgsm_results[0.01] - fgsm_results[0.01])*100:+.2f} percentage points\")\n",
        "    print(f\"   Clean Accuracy Trade-off:  {(adv_clean_acc - clean_acc)*100:+.2f} percentage points\")\n",
        "\n",
        "    # Calculate trade-off ratio\n",
        "    robustness_gain = (adv_pgd_acc - pgd_acc) * 100\n",
        "    clean_loss = abs((adv_clean_acc - clean_acc) * 100)\n",
        "    if clean_loss > 0:\n",
        "        trade_off_ratio = robustness_gain / clean_loss\n",
        "        print(f\"   Trade-off Ratio:          {trade_off_ratio:.2f}x (robustness gain per accuracy loss)\")\n",
        "\n",
        "    print(\"\\n  TRAINING EFFICIENCY:\")\n",
        "    avg_epoch_time = sum(adv_history['epoch_time']) / len(adv_history['epoch_time'])\n",
        "    total_training_time = sum(adv_history['epoch_time'])\n",
        "    print(f\"   Total Training Time:  {total_training_time/60:.2f} minutes\")\n",
        "    print(f\"   Average per Epoch:    {avg_epoch_time/60:.2f} minutes\")\n",
        "    print(f\"   Samples per Second:   {len(train_loader.dataset) / avg_epoch_time:.1f}\")\n",
        "\n",
        "    print(f\"\\n All results saved to: {config.OUT_DIR}\")\n",
        "    print(\"   - adversarial_trained_model.pth\")\n",
        "    print(\"   - adversarial_results.json\")\n",
        "    print(\"   - adversarial_comparison.png\")\n",
        "    print(\"   - adversarial_training_history.png\")\n",
        "    print(\"   - confusion_matrices.png\")\n",
        "\n",
        "\n",
        "    print(\"ANALYSIS COMPLETE\")\n",
        "\n",
        "\n",
        "    # Generate classification reports\n",
        "    print(\"\\nDETAILED CLASSIFICATION REPORTS:\")\n",
        "    print(\"\\nOriginal Model (Clean Test) \")\n",
        "    print(classification_report(clean_labels, clean_preds,\n",
        "                                target_names=['Real', 'Fake'],\n",
        "                                digits=4))\n",
        "\n",
        "    print(\"\\nOriginal Model (PGD Attack)\")\n",
        "    print(classification_report(pgd_labels, pgd_preds,\n",
        "                                target_names=['Real', 'Fake'],\n",
        "                                digits=4))\n",
        "\n",
        "    print(\"\\nAdversarially Trained Model (PGD Attack)\")\n",
        "    print(classification_report(pgd_labels, adv_pgd_preds,\n",
        "                                target_names=['Real', 'Fake'],\n",
        "                                digits=4))\n",
        "\n",
        "else:\n",
        "    print(\"\\nAdversarial training skipped.\")\n",
        "    print(\"\\nstill can use the Phase 1 results to analyze the original model's vulnerabilities.\")\n",
        "\n",
        "    # Save Phase 1 results only\n",
        "    phase1_results = {\n",
        "        'original_model': {\n",
        "            'clean_accuracy': float(clean_acc),\n",
        "            'fgsm_results': {str(k): float(v) for k, v in fgsm_results.items()},\n",
        "            'pgd_accuracy': float(pgd_acc),\n",
        "            'robustness_drop': float(clean_acc - pgd_acc)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(config.OUT_DIR, 'phase1_results.json'), 'w') as f:\n",
        "        json.dump(phase1_results, f, indent=2)\n",
        "\n",
        "    print(f\"\\nPhase 1 results saved to: {config.OUT_DIR}/phase1_results.json\")\n",
        "\n",
        "    # Generate simple visualization for Phase 1\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "    epsilons = list(fgsm_results.keys())\n",
        "    accuracies = [fgsm_results[e]*100 for e in epsilons]\n",
        "\n",
        "    ax.plot(epsilons, accuracies, 'o-', linewidth=2, markersize=10, color='steelblue')\n",
        "    ax.axhline(y=clean_acc*100, color='green', linestyle='--', linewidth=2, label='Clean Accuracy')\n",
        "    ax.axhline(y=pgd_acc*100, color='red', linestyle='--', linewidth=2, label='PGD Accuracy')\n",
        "\n",
        "    ax.set_xlabel('FGSM Epsilon (ε)', fontsize=12)\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax.set_title('Original Model: Adversarial Robustness Analysis', fontsize=14, fontweight='bold')\n",
        "    ax.legend(fontsize=11)\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.set_ylim([0, 105])\n",
        "\n",
        "    # Annotate points\n",
        "    for i, (eps, acc) in enumerate(zip(epsilons, accuracies)):\n",
        "        ax.annotate(f'{acc:.1f}%',\n",
        "                   xy=(eps, acc),\n",
        "                   xytext=(0, 10),\n",
        "                   textcoords='offset points',\n",
        "                   ha='center',\n",
        "                   fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUT_DIR, 'phase1_robustness_curve.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(\"Robustness curve saved\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    print(\"PHASE 1 ANALYSIS COMPLETE\")\n",
        "\n",
        "\n",
        "\n",
        "#print(\" NEXT STEPS:\")\n",
        "\n",
        "#print(\"\\n1. Review the generated visualizations\")\n",
        "#print(\"2. Check adversarial_results.json for detailed metrics\")\n",
        "#print(\"3. Compare original vs adversarially trained model performance\")\n",
        "#print(\"4. Consider testing on additional datasets for generalization\")\n",
        "#print(\"5. Experiment with different epsilon values or attack methods\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jDp71ZHqK1X6",
        "outputId": "dd815415-ee26-45ce-b0ec-8918f780abf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADVERSARIAL ROBUSTNESS ANALYSIS\n",
            "\n",
            "Device: cuda\n",
            "GPU: Tesla T4\n",
            "Mixed Precision: True\n",
            "Output Directory: /content/drive/MyDrive/CombinedDataset/adversarial_results\n",
            "LOADING DATASETS\n",
            "\n",
            "Test:  2425 samples (76 batches)\n",
            "Train: 20960 samples (655 batches)\n",
            "Val:   2430 samples (76 batches)\n",
            "\n",
            "Loading model...\n",
            "Model loaded from: /content/drive/MyDrive/CombinedDataset/results_resnet18/best_resnet18.pth\n",
            "PHASE 1: ORIGINAL MODEL EVALUATION\n",
            "\n",
            "1. Clean Test Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Accuracy: 99.96%\n",
            "\n",
            "2. FGSM Attack Results:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ε = 0.001: 60.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ε = 0.005: 0.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ε = 0.010: 0.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ε = 0.020: 0.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ε = 0.050: 0.62%\n",
            "\n",
            "3. PGD Attack Result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Accuracy: 0.00%\n",
            "   Attack Time: 79.0 seconds\n",
            "ORIGINAL MODEL SUMMARY\n",
            "Clean Accuracy:        99.96%\n",
            "FGSM-0.01 Accuracy:    0.08%\n",
            "PGD-0.01 Accuracy:     0.00%\n",
            "Robustness Drop (PGD): 99.96%\n",
            "PHASE 2: ADVERSARIAL TRAINING\n",
            "\n",
            "Proceed with adversarial training? (y/n): y\n",
            "\n",
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4000081268.py:258: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler() if config.USE_AMP and torch.cuda.is_available() else None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: /content/drive/MyDrive/CombinedDataset/results_resnet18/best_resnet18.pth\n",
            "ADVERSARIAL TRAINING (OPTIMIZED)\n",
            "Optimizer: Adam (LR=0.0001)\n",
            "Mixed Precision: Enabled\n",
            "Training Epsilon: 0.01\n",
            "Epochs: 10\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/655 [00:00<?, ?it/s]/tmp/ipython-input-4000081268.py:306: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4000081268.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Train with adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0madv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;31m# =============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4000081268.py\u001b[0m in \u001b[0;36madversarial_training\u001b[0;34m(model, train_loader, val_loader, config)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}